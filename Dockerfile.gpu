FROM nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04

# Prevent interactive prompts during package installation
ENV DEBIAN_FRONTEND=noninteractive

# Install Python 3.11 and system dependencies
RUN apt-get update && apt-get install -y \
    software-properties-common \
    && add-apt-repository ppa:deadsnakes/ppa \
    && apt-get update && apt-get install -y \
    python3.11 \
    python3.11-venv \
    python3.11-dev \
    python3-pip \
    ffmpeg \
    libsndfile1 \
    git \
    build-essential \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.11 as default
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1 && \
    update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1

# Install uv
COPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv

# Set working directory
WORKDIR /app

# Install Python dependencies (GPU/CUDA versions) - Install torch first!
# Using torch >= 2.6 with CUDA 12.4 support
RUN uv pip install --system --no-cache-dir --upgrade pip && \
    uv pip install --system --no-cache-dir torch>=2.6.0 torchaudio>=2.6.0 --index-url https://download.pytorch.org/whl/cu124

# Copy common requirements
COPY requirements-common.txt .
RUN uv pip install --system --no-cache-dir --prerelease=allow -r requirements-common.txt

# Install Faster Whisper if requested
ARG INSTALL_FASTER_WHISPER=true
COPY requirements-faster-whisper.txt .
RUN if [ "$INSTALL_FASTER_WHISPER" = "true" ]; then \
    uv pip install --system --no-cache-dir -r requirements-faster-whisper.txt; \
    fi

# Install Omnilingual if requested
ARG INSTALL_OMNILINGUAL=true
COPY requirements-omnilingual.txt .
RUN if [ "$INSTALL_OMNILINGUAL" = "true" ]; then \
    uv pip install --system --no-cache-dir -r requirements-omnilingual.txt; \
    fi

# Download NLTK data
RUN python -c "import nltk; nltk.download('punkt'); nltk.download('punkt_tab')"

# Copy application code
COPY app/ ./app/

# Create non-root user (same as CPU version)
RUN useradd -u 10000 -m runner && \
    chown -R runner:runner /app

# Create cache directory for model downloads
RUN mkdir -p /home/runner/.cache && \
    chown -R runner:runner /home/runner/.cache

# Environment variables with defaults
ENV ASR_MODEL=omniASR_LLM_Unlimited_7B_v2
ENV ASR_DEVICE=cuda
ENV ASR_COMPUTE_TYPE=float16
ENV ENABLE_STEMMING=false
ENV SUPPRESS_NUMERALS=true
ENV BATCH_SIZE=8
ENV HOME=/tmp
ENV FLASHINFER_WORKSPACE_BASE=/tmp/flashinfer
ENV XDG_CACHE_HOME=/tmp/.cache
ENV XDG_CONFIG_HOME=/tmp/.config
ENV HF_HOME=/tmp/huggingface
ENV TORCH_HOME=/tmp/torch
ENV TRITON_CACHE_DIR=/tmp/triton
ENV VLLM_CACHE_DIR=/tmp/vllm_cache
ENV NEMO_CACHE_DIR=/tmp/nemo
ENV MPLCONFIGDIR=/tmp/matplotlib

# Copy startup script
COPY startup.sh /app/startup.sh
RUN chmod +x /app/startup.sh

# Expose port
EXPOSE 8080

# Run the application via startup script
ENTRYPOINT ["/app/startup.sh"]
